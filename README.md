# Список моделей LLM для локального использования

Этот список включает модели LLM (Large Language Models) с открытым исходным кодом, доступные для локального развертывания. Модели охватывают различные языки, включая русский и китайский, и могут быть использованы для широкого спектра задач, таких как генерация текста, анализ, кодирование и другие. В таблице указаны их характеристики, размеры файлов, лицензии и ссылки для скачивания.

# Список моделей LLM для локального использования

| **Model Name**             | **Description**                                                               | **Parameter Size** | **File Size**  | **License**   | **Source**     | **Download Link**                                                               |
|----------------------------|-------------------------------------------------------------------------------|--------------------|----------------|---------------|----------------|--------------------------------------------------------------------------------|
| **RuGPT-3.5 13B**          | Русскоязычная версия GPT-3.5 с 13 миллиардами параметров.                     | 13B                | ~7.45 GB       | MIT           | AI Forever     | [Hugging Face](https://huggingface.co/ai-forever/ruGPT-3.5-13B)                |
| **Vikhr**                  | Модели, ориентированные на русский язык, с улучшенной производительностью.    | various            | ~6.97 GB       | OpenRAIL-M    | Vikhr          | [Hugging Face](https://huggingface.co/IlyaGusev/vikhr-13b)                     |
| **T-Lite и T-Pro**         | Модели, адаптированные для русского языка с использованием технологии Continual Pretraining. | various            | ~7.61 GB       | OpenRAIL-M    | T-Tech         | [Hugging Face](https://huggingface.co/t-tech)                                   |
| **GigaChat**               | Модели с 100 миллиардами параметров, обученные на русском и английском языках. | 100B               | ~20.6 GB       | Proprietary   | Yandex         | [Официальный сайт](https://yandex.ru/gigachat)                                 |
| **YaLM-100B**              | Русскоязычная модель от Yandex с 100B параметрами.                            | 100B               | ~200 GB        | Apache 2.0    | Yandex         | [Hugging Face](https://huggingface.co/Yandex/YaLM-100B)                        |
| **LLaMA 2 7B**             | Модели с открытым исходным кодом от Meta.                                      | 7B                 | ~13GB          | Llama 2       | Meta           | [Hugging Face](https://huggingface.co/meta-llama/Llama-2-7b-hf)                |
| **Mistral 7B**             | Модели с открытым исходным кодом, оптимизированные для быстродействия.        | 7.3B               | ~13.74 GB      | Apache 2.0    | Mistral AI     | [Hugging Face](https://huggingface.co/mistralai/Mistral-7B-v0.1)               |
| **BLOOMZ 7B**              | Модель для многоязычных задач, поддерживающая китайский и другие языки.       | 7.1B               | ~13.17 GB      | OpenRAIL-M    | BigScience     | [Hugging Face](https://huggingface.co/bigscience/bloomz-7b1-mt)                |
| **GPT-NeoX-20B**           | Модель с открытым исходным кодом для обработки большого объема текста.        | 20B                | ~40 GB         | Apache 2.0    | EleutherAI     | [Hugging Face](https://huggingface.co/EleutherAI/gpt-neox-20b)                 |
| **mistral-7b-instruct**    | Инструктивная версия Mistral 7B.                                              | 7B                 | ~14 GB         | Apache 2.0    | Mistral AI     | [Hugging Face](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)      |
| **codestral-22b**          | Модель для генерации кода с поддержкой 80 языков программирования.            | 22B                | ~44 GB         | Mistral       | Mistral AI     | [Hugging Face](https://huggingface.co/mistralai/Codestral-22B-v0.1)            |
| **phi-2**                  | Компактная модель от Microsoft с 2.7B параметрами.                            | 2.7B               | ~5.5 GB        | MIT           | Microsoft      | [Hugging Face](https://huggingface.co/microsoft/phi-2)                         |
| **Qwen1.5 7B**             | Многоязычная модель от Alibaba.                                               | 7B                 | ~14 GB         | Apache 2.0    | Alibaba        | [Hugging Face](https://huggingface.co/Qwen/Qwen1.5-7B)                         |
| **Gemma 7B**               | Легковесная модель от Google.                                                 | 7B                 | ~14 GB         | Gemma         | Google         | [Hugging Face](https://huggingface.co/google/gemma-7b)                         |
| **LLaMA 3 70B**            | Флагманская модель Meta с 70B параметрами.                                    | 70B                | ~140 GB        | Llama 3       | Meta           | [Hugging Face](https://huggingface.co/meta-llama/Meta-Llama-3-70B)             |
| **DeepSeek 7B**            | Модель для кодирования и общего назначения.                                   | 7B                 | ~14 GB         | Apache 2.0    | DeepSeek       | [Hugging Face](https://huggingface.co/deepseek-ai/deepseek-llm-7b)             |
